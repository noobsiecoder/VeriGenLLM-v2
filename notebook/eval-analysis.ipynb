{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0681e03a",
   "metadata": {},
   "source": [
    "This Jupyter notebook contains all code to data visualization of the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be33b1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../dataset/evals/comparisons_pass_10/Claude_Opus4_table.csv\n",
      "\n",
      "Creating table for model: Claude Opus4\n",
      "            Avg Pass@10 (compile)  Avg Pass@10 (corr)  Avg Pass@10 (synth)\n",
      "Difficulty                                                                \n",
      "basic                       0.600               1.000                0.600\n",
      "medium                      0.875               0.625                0.875\n",
      "hard                        1.000               0.400                1.000\n",
      "../dataset/evals/comparisons_pass_10/CodeLlama_7B_Ins_(no-sm)_table.csv\n",
      "\n",
      "Creating table for model: CodeLlama 7B Ins (no-sm)\n",
      "            Avg Pass@10 (compile)  Avg Pass@10 (corr)  Avg Pass@10 (synth)\n",
      "Difficulty                                                                \n",
      "basic                        1.00                0.80                  1.0\n",
      "medium                       0.75                0.25                  1.0\n",
      "hard                         1.00                0.20                  1.0\n",
      "../dataset/evals/comparisons_pass_10/Deepseek_Coder_7B_Ins_v1.5_table.csv\n",
      "\n",
      "Creating table for model: Deepseek Coder 7B Ins v1.5\n",
      "            Avg Pass@10 (compile)  Avg Pass@10 (corr)  Avg Pass@10 (synth)\n",
      "Difficulty                                                                \n",
      "basic                         0.8                 1.0                  0.8\n",
      "medium                        1.0                 0.5                  1.0\n",
      "hard                          1.0                 0.6                  1.0\n",
      "../dataset/evals/comparisons_pass_10/OpenAI_GPT4.1_table.csv\n",
      "\n",
      "Creating table for model: OpenAI GPT4.1\n",
      "            Avg Pass@10 (compile)  Avg Pass@10 (corr)  Avg Pass@10 (synth)\n",
      "Difficulty                                                                \n",
      "basic                       0.800               1.000                0.800\n",
      "medium                      0.875               0.625                0.875\n",
      "hard                        0.600               0.200                0.600\n",
      "../dataset/evals/comparisons_pass_10/Qwen_Coder2.5_7B_Instruct_table.csv\n",
      "\n",
      "Creating table for model: Qwen Coder2.5 7B Instruct\n",
      "            Avg Pass@10 (compile)  Avg Pass@10 (corr)  Avg Pass@10 (synth)\n",
      "Difficulty                                                                \n",
      "basic                        0.80               0.600                  0.8\n",
      "medium                       0.75               0.375                  1.0\n",
      "hard                         1.00               0.400                  1.0\n",
      "Script ready for multiple JSON file comparison!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from math import comb\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def load_json_data(file_path):\n",
    "    \"\"\"Load JSON data from file\"\"\"\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "def create_individual_tables(\n",
    "    file_paths: List[str], output_dir: str, file_labels: List[str] = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Create separate individual tables for each JSON file\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    file_paths:     List[str]\n",
    "        List of paths to JSON files\n",
    "    output_dir:    str\n",
    "        Name of output directory path\n",
    "    file_labels:    List[str]\n",
    "        Optional list of labels for each file\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Use custom labels or default to File 1, File 2, etc.\n",
    "    if file_labels is None:\n",
    "        file_labels = [f\"File {i + 1}\" for i in range(len(file_paths))]\n",
    "\n",
    "    all_dataframes = []\n",
    "\n",
    "    # Process each file separately\n",
    "    for idx, (path, label) in enumerate(zip(file_paths, file_labels)):\n",
    "        # Load data\n",
    "        data = load_json_data(path)\n",
    "        # Ensure data is in list format\n",
    "        if not isinstance(data, list):\n",
    "            data = [data]\n",
    "\n",
    "        # Create column headers for this file\n",
    "        columns = [\n",
    "            \"Question\",\n",
    "            \"Difficulty\",\n",
    "            \"n\",\n",
    "            \"compile\",\n",
    "            \"func-corr\",\n",
    "            \"synth\",\n",
    "        ]\n",
    "\n",
    "        # Create table data\n",
    "        table_data = []\n",
    "\n",
    "        for item in data:\n",
    "            # Truncate long questions\n",
    "            question = item[\"question\"]\n",
    "            if len(question) > 60:\n",
    "                question = question[:57] + \"...\"\n",
    "\n",
    "            row = [\n",
    "                question,\n",
    "                item[\"difficulty\"],\n",
    "                item[\"evals\"][\"n\"],\n",
    "                item[\"evals\"][\"compile\"],\n",
    "                item[\"evals\"][\"func-corr\"],\n",
    "                item[\"evals\"][\"synth\"],\n",
    "            ]\n",
    "            table_data.append(row)\n",
    "\n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(table_data, columns=columns)\n",
    "        all_dataframes.append(df)\n",
    "\n",
    "        # Create figure\n",
    "        fig_width = 14\n",
    "        fig_height = min(20, len(df) * 0.5 + 2)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "        ax.axis(\"tight\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "        # Create table\n",
    "        table = ax.table(\n",
    "            cellText=df.values, colLabels=df.columns, cellLoc=\"center\", loc=\"center\"\n",
    "        )\n",
    "\n",
    "        # Style the table\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(9)\n",
    "        table.scale(1.2, 1.5)\n",
    "\n",
    "        # Color header row\n",
    "        for i in range(len(columns)):\n",
    "            table[(0, i)].set_facecolor(\"#4CAF50\")\n",
    "            table[(0, i)].set_text_props(weight=\"bold\", color=\"white\")\n",
    "\n",
    "        # Color alternating rows\n",
    "        for i in range(1, len(df) + 1):\n",
    "            if i % 2 == 0:\n",
    "                for j in range(len(columns)):\n",
    "                    table[(i, j)].set_facecolor(\"#f0f0f0\")\n",
    "\n",
    "        # Adjust column widths\n",
    "        cellDict = table.get_celld()\n",
    "        for i in range(len(df) + 1):\n",
    "            cellDict[(i, 0)].set_width(0.4)  # Question column wider\n",
    "            cellDict[(i, 1)].set_width(0.1)  # Difficulty\n",
    "            for j in range(2, len(columns)):\n",
    "                cellDict[(i, j)].set_width(0.1)\n",
    "\n",
    "        plt.title(\n",
    "            f\"{label} - Evaluation Results\", fontsize=16, fontweight=\"bold\", pad=6\n",
    "        )\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save files\n",
    "        output_filepath = os.path.join(\n",
    "            output_dir, f\"{label.replace(' ', '_')}_table.png\"\n",
    "        )\n",
    "        plt.savefig(output_filepath, dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close()  # Close figure to free memory\n",
    "\n",
    "        # Save as CSV\n",
    "        csv_file = output_filepath.replace(\".png\", \".csv\")\n",
    "        df.to_csv(csv_file, index=False)\n",
    "\n",
    "        print(f\"Table for {label} saved as {output_filepath}\")\n",
    "        print(f\"CSV for {label} saved as {csv_file}\")\n",
    "\n",
    "    return all_dataframes\n",
    "\n",
    "\n",
    "def pass_at_k(n, c, k):\n",
    "    \"\"\"Compute Pass@k probability given n completions, c correct.\"\"\"\n",
    "    if pd.isna(n) or pd.isna(c):\n",
    "        return None\n",
    "    n = int(n)\n",
    "    c = int(c)\n",
    "    if n - c < k:\n",
    "        return 1.0\n",
    "    return 1 - comb(n - c, k) / comb(n, k)\n",
    "\n",
    "\n",
    "def create_comparison_summary(\n",
    "    file_paths: List[str],\n",
    "    output_path: str,\n",
    "    file_labels: List[str] = None,\n",
    "    k: int = 5,\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a summary table showing aggregated metrics for each file\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    file_paths:     List[str]\n",
    "        List of paths to JSON files\n",
    "    output_path:    str\n",
    "        Output filepath\n",
    "    file_labels:    List[str]\n",
    "        Optional list of labels for each file\n",
    "    k:              int\n",
    "        Number of samples to check\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Load data from all files\n",
    "    all_data = []\n",
    "    for path in file_paths:\n",
    "        data = load_json_data(path)\n",
    "        if not isinstance(data, list):\n",
    "            data = [data]\n",
    "        all_data.append(data)\n",
    "\n",
    "    # Use custom labels or default\n",
    "    if file_labels is None:\n",
    "        file_labels = [f\"File {i + 1}\" for i in range(len(file_paths))]\n",
    "\n",
    "    # Calculate summary statistics\n",
    "    summary_data = []\n",
    "\n",
    "    for idx, data in enumerate(all_data):\n",
    "        total_questions = len(data)\n",
    "        avg_compile = (\n",
    "            sum(\n",
    "                pass_at_k(item[\"evals\"][\"n\"], item[\"evals\"][\"compile\"], k)\n",
    "                for item in data\n",
    "            )\n",
    "            / total_questions\n",
    "        )\n",
    "\n",
    "        avg_func_corr = (\n",
    "            sum(\n",
    "                pass_at_k(item[\"evals\"][\"n\"], item[\"evals\"][\"func-corr\"], k)\n",
    "                for item in data\n",
    "            )\n",
    "            / total_questions\n",
    "        )\n",
    "\n",
    "        avg_synth = (\n",
    "            sum(\n",
    "                pass_at_k(item[\"evals\"][\"n\"], item[\"evals\"][\"synth\"], k)\n",
    "                for item in data\n",
    "            )\n",
    "            / total_questions\n",
    "        )\n",
    "\n",
    "        summary_data.append(\n",
    "            [\n",
    "                file_labels[idx],\n",
    "                total_questions,\n",
    "                f\"{avg_compile:.4f}\",\n",
    "                f\"{avg_func_corr:.4f}\",\n",
    "                f\"{avg_synth:.4f}\",\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # Create DataFrame\n",
    "    columns = [\n",
    "        \"File\",\n",
    "        \"Total Questions\",\n",
    "        f\"Avg pass@{k}-compile\",\n",
    "        f\"Avg pass@{k}-func-corr\",\n",
    "        f\"Avg pass@{k}-synth\",\n",
    "    ]\n",
    "    df_summary = pd.DataFrame(summary_data, columns=columns)\n",
    "\n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(12, len(df_summary) * 0.8 + 2))\n",
    "    ax.axis(\"tight\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    # Create table\n",
    "    table = ax.table(\n",
    "        cellText=df_summary.values,\n",
    "        colLabels=df_summary.columns,\n",
    "        cellLoc=\"center\",\n",
    "        loc=\"center\",\n",
    "    )\n",
    "\n",
    "    # Style the table\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1.2, 1.8)\n",
    "\n",
    "    # Color header row\n",
    "    for i in range(len(columns)):\n",
    "        table[(0, i)].set_facecolor(\"#2196F3\")\n",
    "        table[(0, i)].set_text_props(weight=\"bold\", color=\"white\")\n",
    "\n",
    "    # Color alternating rows\n",
    "    for i in range(1, len(df_summary) + 1):\n",
    "        if i % 2 == 0:\n",
    "            for j in range(len(columns)):\n",
    "                table[(i, j)].set_facecolor(\"#f0f0f0\")\n",
    "\n",
    "    plt.title(\n",
    "        f\"Summary Statistics Across Files for Pass@{k}\",\n",
    "        fontsize=16,\n",
    "        fontweight=\"bold\",\n",
    "        pad=2,\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        os.path.join(output_path, f\"summary_pass_{k}.png\"), dpi=300, bbox_inches=\"tight\"\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "    return df_summary\n",
    "\n",
    "\n",
    "def create_difficulty_lvl_summary(output_path: str, model_labels: List[str] = None, k: int = 5):\n",
    "    \"\"\"\n",
    "    Create table showing avg Pass@k metric for each level of difficulty per questions (for each LLM)\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    output_path:     str\n",
    "        Output filepath \n",
    "    model_labels:    List[str]\n",
    "        Model labels containing model name - used in reading CSV file(s)\n",
    "    k:              int\n",
    "        Number of samples to check\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "    \"\"\"\n",
    "    for model_label in model_labels:\n",
    "        csv_filepath = os.path.join(\n",
    "            output_path, f\"{model_label.replace(' ', '_')}_table.csv\"\n",
    "        )\n",
    "\n",
    "        print(csv_filepath)\n",
    "\n",
    "        if not os.path.exists(csv_filepath):\n",
    "            print(\"CSV Data of Pass@k metric doesn't exist. Try running again\")\n",
    "            continue\n",
    "\n",
    "        df = pd.read_csv(csv_filepath)\n",
    "\n",
    "        # Compute true Pass@k per row for each metric\n",
    "        df[\"compile\"] = df.apply(\n",
    "            lambda row: pass_at_k(row[\"n\"], row[\"compile\"], k), axis=1\n",
    "        )\n",
    "        df[\"func_corr\"] = df.apply(\n",
    "            lambda row: pass_at_k(row[\"n\"], row[\"func-corr\"], k), axis=1\n",
    "        )\n",
    "        df[\"synth\"] = df.apply(lambda row: pass_at_k(row[\"n\"], row[\"synth\"], k), axis=1)\n",
    "\n",
    "        # Group by difficulty and average probabilities\n",
    "        difficulty_order = [\"basic\", \"medium\", \"hard\"]\n",
    "        summary_df = (\n",
    "            df.groupby(\"Difficulty\", sort=False)[[\"compile\", \"func_corr\", \"synth\"]]\n",
    "            .mean()\n",
    "            .round(4)\n",
    "            .reindex(difficulty_order)\n",
    "        )\n",
    "\n",
    "        if summary_df.empty:\n",
    "            print(f\"No data to display for {model_label}\")\n",
    "            continue\n",
    "\n",
    "        summary_df.columns = [\n",
    "            f\"Avg Pass@{k} ({col.split('_')[-1]})\" for col in summary_df.columns\n",
    "        ]\n",
    "\n",
    "        print(f\"\\nCreating table for model: {model_label}\")\n",
    "        print(summary_df)\n",
    "\n",
    "        # Plotting (same as your original plotting logic)\n",
    "        col_labels = [\"Difficulty\"] + list(summary_df.columns)\n",
    "        cell_text = [\n",
    "            [idx] + list(row) for idx, row in zip(summary_df.index, summary_df.values)\n",
    "        ]\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(12, len(summary_df) * 0.8 + 2))\n",
    "        ax.axis(\"off\")\n",
    "        table = ax.table(cellText=cell_text, colLabels=col_labels, loc=\"center\")\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(10)\n",
    "        table.scale(0.8, 1.8)\n",
    "\n",
    "        for i in range(len(col_labels)):\n",
    "            table[(0, i)].set_facecolor(\"#2196F3\")\n",
    "            table[(0, i)].set_text_props(weight=\"bold\", color=\"white\")\n",
    "\n",
    "        for i in range(1, len(summary_df) + 1):\n",
    "            cell = table[(i, 0)]\n",
    "            capitalized_text = cell.get_text().get_text().title()\n",
    "            cell.get_text().set_text(capitalized_text)\n",
    "            cell.set_text_props(weight=\"bold\", ha=\"center\", va=\"center\")\n",
    "\n",
    "        ax.set_title(\n",
    "            f\"Difficulty-Level Pass@{k} Summary for {model_label}\",\n",
    "            fontsize=14,\n",
    "            fontweight=\"bold\",\n",
    "            pad=12,\n",
    "        )\n",
    "\n",
    "        filename = f\"{model_label.replace(' ', '_')}_diff_summary.png\"\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_path, filename), dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "def find_json_files(directory: str):\n",
    "    \"\"\"\n",
    "    Find all JSON files in a directory\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    directory:  str\n",
    "        Directory (path)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "    \"\"\"\n",
    "    json_files = []\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".json\"):\n",
    "            json_files.append(os.path.join(directory, file))\n",
    "    return sorted(json_files)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Example 1: Compare specific files\n",
    "    eval_dataset_path = \"dataset/evals\"\n",
    "    target = os.path.join(\"..\", eval_dataset_path)\n",
    "\n",
    "    file_paths = find_json_files(target)\n",
    "    labels = [\n",
    "        \"Claude Opus4\",\n",
    "        \"CodeLlama 7B Ins (no-sm)\",\n",
    "        \"Deepseek Coder 7B Ins v1.5\",\n",
    "        \"OpenAI GPT4.1\",\n",
    "        \"Qwen Coder2.5 7B Instruct\",\n",
    "    ]\n",
    "\n",
    "    # Number of samples to check\n",
    "    k = 10\n",
    "\n",
    "    # Uncomment to run:\n",
    "    create_individual_tables(\n",
    "        file_paths,\n",
    "        os.path.join(\"..\", eval_dataset_path, f\"comparisons_pass_{k}\"),\n",
    "        labels,\n",
    "    )\n",
    "    create_comparison_summary(\n",
    "        file_paths,\n",
    "        os.path.join(\"..\", eval_dataset_path, f\"comparisons_pass_{k}\"),\n",
    "        labels,\n",
    "        k=k,\n",
    "    )\n",
    "    create_difficulty_lvl_summary(\n",
    "        os.path.join(\"..\", eval_dataset_path, f\"comparisons_pass_{k}\"), labels, k=k\n",
    "    )\n",
    "    print(\"Script ready for multiple JSON file comparison!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "verigenllm-v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
